# Vulnerability Detection Module

## Plan

- Techniques
  - Fuzzing
  - Symbolic execution
- As a system
  - Input data structures
  - Output data structures
- Fuzzing
  - Fuzzer model
  - Fuzzing arguments with custom adapter for AFL++
- Technologies
  - afl++
  - QBDI
  - Docker
- CLI

## Existent Content

\subsection{Fuzzing Standard Input and Files}

\subsubsection{Introduction}

The purpose of the vulnerability detection module is to use all the previously-detected input streams of the given executable in order to detect its vulnerabilities. The latter consists in the path of the control flow graph (abbreviated CFG) which are not implemented correctly.

The issue that can emerge is the \textbf{path explosion}, a problem specific for techniques such as symbolic execution. As symbolic values are propagated on each path of the graph, the complexity of finding vulnerabilities in such a large set of data is unfeasible considering the limitations in memory and computation power.

We proceed to overcome this by using \textbf{fuzzing}. The sending of random inputs on each input stream make the execution flow on various paths, with various input variables. The probability of triggering a vulnerability residing in the bytecode could be then increased.

Another important constraint for fuzzing is the \textbf{blackbox aspect} of the CRS: the vulnerability discovery module does not have access to the source code of the executable, but only at the binary itself. This limited our search as multiple fuzzers uses source code instrumentation, namely introducing small pieces of code before the compilation stage such that, at execution, the fuzzer can know which path of the CFG was reached by the execution.

Firstly, we considered american fuzzy lop (abbreviated AFL) \cite{afl} as a state-of-the-art blackbox fuzzer that we can integrate in the cyber reasoning system, but the Google's upstream has no development activity since June 2021. A promising alternative is a fork of it, \textbf{afl++} \cite{aflplusplus}, which is continuously developed by the open source community and supports features like:
\begin{itemize}
    \item QEMU emulation for deducing relevant information (for example, coverage) on runtime, without a hard requirement for source code instrumentation before compilation;
    \item Persistent mode for specifying a section of the code segment that should be executed in a loop by the fuzzer, without the need of creating a process each time new inputs should be provided to the executable; and
    \item Greater speed, resulting in more mutations in the fuzzing engine.
\end{itemize}

\subsubsection{Architecture. Implementation}

Our implementation started by considering a subset of all possible \textbf{input streams} that an executable could have:
\begin{itemize}
    \item Opened and written/read files;
    \item Standard input; and
    \item Arguments, that are used to specify startup information such as filenames and generic strings.
\end{itemize}

The architecture in this section will cover only the first two, the arguments being detailed in a next subchapter.

As previously mentioned, afl++ was chosen as a de-facto blackbox fuzzing tool. We created a custom Docker image to be its environment, the purpose being isolation and easy regeneration. It is \textbf{orchestrated via Python} code to be automatically built, instantiated, attached to volumes (for target executable, sample inputs and analysis).

Furthermore, the same Python code started \mintinline{text}{afl-fuzz} inside the created \textbf{container} to fuzz the provided target executable with the sample inputs (if any). These are mutated and passed to standard input or placed in files (two input streams that are supported by default by afl++), data that is consumed by the binary.

When a new crash is detected by afl++, a new file is created in the analysis directory, which is continuously monitored by a Python watchdog. The crash is processed to create a new instance of a data structure that represents a proof of vulnerability. In the future implementations, it will be passed to the next modules (for example, the vulnerability analysis, that will analyze the root cause and the affected internals of the executable).

> About fuzzing standard input and files
> Source: second report

\subsection{Arguments Fuzzing with AFL++}

As mentioned in the previous report, the research regarding arguments fuzzing was slowed down due to technological choice. We managed to overcome this issue by integrating AFL++ into our cyber reasoning system. At the end of last semester, it executed fuzzing only over files and standard input.

We managed to detect the arguments with a custom implementation based on QBDI, a dynamic binary instrumentation engine. The remaining part was the generation of random inputs to be passed directly as arguments, in the vulnerability discovery module. We describe the solution in the last report.

To accomplish this task, the same \textbf{Docker image} from files and standard input fuzzing was used. The main difference is that the fuzzed binary is not the target binary anymore, but a \textbf{custom adapter} built in C. It takes the random input generated by AFL++ from \mintinline{text}{stdin}. Then, the input is tokenized by using space (\mintinline{text}{0x20} ASCII) as a delimiter, and the resulted \mintinline{text}{char *} sequence is used as \mintinline{text}{argv} for an \mintinline{text}{execve} syscall.

The initial image of the process, as it is created by the fuzzer, is the adapter's image. By using the described approach, the syscall replaces the process image with the real target binary's one, having as arguments a random string of characters. An arguments' mismanagement can cause a crash. AFL++ will be able to detect and report it.

> About fuzzing arguments
> Source: third report
